{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev stat 22666633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "d = '../data/pre/' # raw data directory\n",
    "print('dev stat 22666633')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, Callback\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, SimpleRNN, BatchNormalization\n",
    "from keras.layers import Dropout, Bidirectional, Flatten, Input, Reshape\n",
    "from keras.layers.merge import Concatenate, Add, concatenate, add\n",
    "\n",
    "ac = pd.read_csv('%sapp_categories.csv' % d)\n",
    "ui = pd.read_csv('%suser_installedapps.csv' % d)\n",
    "ua = pd.read_csv('%suser_app_actions.csv' % d)\n",
    "\n",
    "tr_ori = pd.read_csv('../data/pre/new_generated_train.csv', index_col=0)\n",
    "te_ori = pd.read_csv('../data/pre/new_generated_test.csv', index_col=0)\n",
    "# features = [ 'positionType', 'connectionType', 'age', 'haveBaby', 'telecomsOperator',\n",
    "#             'gender', 'education', 'clickTime_h', 'clickTime_d', 'weekDay',\n",
    "#             'marriageStatus', 'appPlatform', 'clickTime_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43  40  21 ...,  21 486 238]\n",
      "1073194\n",
      "1073200\n",
      "1073205\n",
      "1073175\n",
      "1073220\n",
      "1073222\n",
      "1073202\n",
      "1073219\n",
      "1072683\n",
      "1073219\n",
      "1073095\n",
      "1073121\n",
      "1073212\n",
      "1073220\n",
      "1073144\n",
      "1073210\n",
      "1072377\n",
      "1073203\n",
      "1073222\n",
      "1073220\n",
      "1073210\n",
      "1073222\n",
      "1073204\n",
      "1073220\n",
      "1073193\n",
      "1073220\n",
      "1073212\n",
      "1070403\n",
      "1073222\n",
      "1073222\n",
      "1073173\n",
      "1073215\n",
      "1071064\n",
      "1073196\n",
      "1073196\n",
      "1073196\n",
      "1071850\n",
      "1073058\n",
      "1073160\n",
      "1073220\n",
      "1073203\n",
      "1073212\n",
      "1073174\n",
      "1073184\n",
      "1073204\n",
      "1073220\n",
      "1073194\n",
      "1072569\n",
      "1073110\n",
      "1073220\n",
      "1073203\n",
      "1073210\n",
      "1073176\n",
      "1073157\n",
      "1072084\n",
      "1073220\n",
      "1072812\n",
      "1071252\n",
      "1073160\n",
      "1073196\n",
      "1073206\n",
      "1073176\n",
      "1073208\n",
      "1073196\n",
      "1073216\n",
      "1073184\n",
      "1071322\n",
      "1072803\n",
      "1073196\n",
      "1072526\n",
      "1073190\n",
      "1073184\n",
      "1073216\n",
      "1073214\n",
      "1073205\n",
      "1073193\n",
      "1071884\n",
      "1071202\n",
      "1073142\n",
      "1073220\n",
      "1073214\n",
      "1040300\n",
      "1073029\n",
      "1073197\n",
      "1073202\n",
      "1073200\n",
      "1073214\n",
      "1073220\n",
      "1073220\n",
      "1073222\n",
      "1073184\n",
      "1073163\n",
      "1073088\n",
      "1073175\n",
      "1073215\n",
      "1073038\n",
      "1073214\n",
      "1073193\n",
      "1073205\n",
      "1073222\n",
      "1073196\n",
      "1073072\n",
      "1073220\n",
      "1072764\n",
      "1073205\n",
      "1073184\n",
      "1073024\n",
      "1073214\n",
      "1073193\n",
      "1073214\n",
      "1073198\n",
      "1073214\n",
      "1072904\n",
      "1072800\n",
      "1073220\n",
      "1071273\n",
      "1073198\n",
      "1073160\n",
      "1073196\n",
      "1073219\n",
      "1073219\n",
      "1072812\n",
      "1073065\n",
      "1072720\n",
      "1072896\n",
      "1073193\n",
      "1073220\n",
      "1073222\n",
      "1073196\n",
      "1068930\n",
      "1071778\n",
      "1073098\n",
      "1073222\n",
      "1073220\n",
      "1072862\n",
      "1072398\n",
      "1073220\n",
      "1073222\n",
      "1073215\n",
      "1073208\n",
      "1069940\n",
      "1073096\n",
      "977607\n",
      "1073220\n",
      "1073222\n",
      "1073220\n",
      "1073206\n",
      "1073163\n",
      "1073214\n",
      "1073222\n",
      "1073150\n",
      "1073200\n",
      "1073220\n",
      "1072400\n",
      "1073204\n",
      "1068962\n",
      "1072890\n",
      "1073196\n",
      "1073216\n",
      "1073142\n",
      "1073010\n",
      "1073205\n",
      "1073088\n",
      "1073175\n",
      "1073220\n",
      "1052838\n",
      "1073216\n",
      "1073220\n",
      "1073198\n",
      "1073220\n",
      "1073203\n",
      "1073220\n",
      "1073222\n",
      "1073144\n",
      "1073136\n",
      "1073215\n",
      "1072848\n",
      "1073176\n",
      "1073202\n",
      "1073216\n",
      "1073139\n",
      "1073220\n",
      "1072890\n",
      "1073160\n",
      "1073151\n",
      "1072862\n",
      "1073136\n",
      "1073219\n",
      "1073142\n",
      "1073220\n",
      "1073208\n",
      "1071554\n",
      "1073175\n",
      "1073219\n",
      "1073144\n",
      "1073220\n",
      "1071714\n",
      "1073091\n",
      "1073142\n",
      "1073215\n",
      "1073072\n",
      "1072620\n",
      "1073216\n",
      "1073100\n",
      "1073222\n",
      "1073220\n",
      "1073220\n",
      "1073220\n",
      "1073222\n",
      "1072904\n",
      "1073196\n",
      "1072782\n",
      "1073150\n",
      "1073222\n",
      "1073220\n",
      "1073205\n",
      "1073020\n",
      "1073220\n",
      "1073220\n",
      "1072384\n",
      "1073220\n",
      "1073210\n",
      "1072384\n",
      "1073202\n",
      "1073214\n",
      "1073220\n",
      "1073200\n",
      "1073203\n",
      "1072850\n",
      "1073196\n",
      "1073216\n",
      "1073222\n",
      "1073222\n",
      "1073215\n",
      "1073176\n",
      "1073216\n",
      "1073215\n",
      "1073205\n",
      "1073220\n",
      "1073214\n",
      "1073200\n",
      "1073220\n",
      "1072980\n",
      "1073205\n",
      "1073212\n",
      "1073200\n",
      "1072314\n",
      "1072960\n",
      "1073222\n",
      "1073216\n",
      "1073215\n",
      "1073222\n",
      "1073220\n",
      "1073040\n",
      "1073200\n",
      "1073076\n",
      "1072750\n",
      "1073215\n",
      "1072852\n",
      "1073214\n",
      "1073157\n",
      "1073110\n",
      "1073216\n",
      "1073220\n",
      "1073212\n",
      "1073216\n",
      "1073010\n",
      "1073214\n",
      "1073196\n",
      "1073160\n",
      "1073197\n",
      "1073202\n",
      "1073152\n",
      "1073220\n",
      "1073196\n",
      "1073205\n",
      "1073210\n",
      "1073098\n",
      "1072600\n",
      "1073222\n",
      "1068438\n",
      "1073219\n",
      "1073145\n",
      "1073142\n",
      "1073220\n",
      "1073045\n",
      "1073204\n",
      "1072965\n",
      "1073220\n",
      "1073219\n",
      "1073222\n",
      "1073215\n",
      "1073124\n",
      "1073205\n",
      "1073163\n",
      "1073220\n",
      "1073139\n",
      "1072512\n",
      "1072266\n",
      "1073203\n",
      "1073220\n",
      "1073149\n",
      "1073157\n",
      "1073120\n",
      "1073197\n",
      "1073216\n",
      "1073210\n",
      "1073193\n",
      "1073065\n",
      "1073059\n",
      "1073193\n",
      "1073145\n",
      "1073205\n",
      "1073220\n",
      "1073142\n",
      "1073220\n",
      "1073025\n",
      "1073216\n",
      "1073206\n",
      "1073076\n",
      "1073142\n",
      "1073222\n",
      "1073157\n",
      "1073210\n",
      "1071125\n",
      "1073220\n",
      "1073215\n",
      "1073040\n",
      "1073080\n",
      "1073163\n",
      "1073208\n",
      "1073196\n",
      "1073184\n",
      "1073222\n",
      "1073216\n",
      "1073220\n",
      "1073216\n",
      "1073038\n",
      "1073000\n",
      "1073220\n",
      "1073214\n",
      "1073215\n",
      "1073220\n",
      "1073196\n",
      "1073219\n",
      "1073220\n",
      "1073176\n",
      "1073222\n",
      "1073145\n",
      "1073160\n",
      "1073196\n",
      "1073205\n",
      "1073220\n",
      "1073220\n",
      "1068012\n",
      "1073184\n",
      "1073220\n",
      "1073150\n",
      "1072254\n",
      "1073215\n",
      "1072190\n",
      "1073092\n",
      "1071486\n",
      "1073215\n",
      "1073220\n",
      "1073160\n",
      "1073184\n",
      "1073040\n",
      "1073220\n",
      "1072972\n",
      "1073165\n",
      "1072899\n",
      "1073220\n",
      "1073214\n",
      "1073160\n",
      "1073220\n",
      "1073088\n",
      "1073088\n",
      "1073065\n",
      "1073193\n",
      "1073193\n",
      "1073204\n",
      "1073176\n",
      "1073200\n",
      "1073058\n",
      "1073148\n",
      "1073220\n",
      "1073160\n",
      "1073215\n",
      "1073196\n",
      "1073204\n",
      "1073160\n",
      "1073219\n",
      "1073220\n",
      "1022622\n",
      "1073148\n",
      "1073214\n",
      "1073210\n",
      "1073192\n",
      "1072503\n",
      "1073220\n",
      "1073216\n",
      "1073215\n",
      "1073196\n",
      "1073220\n",
      "1073220\n",
      "1073184\n",
      "1073145\n",
      "1073152\n",
      "1073222\n",
      "1073220\n",
      "1073220\n",
      "1073170\n",
      "1073215\n",
      "1073173\n",
      "1073198\n",
      "1073220\n",
      "1073175\n",
      "1072866\n",
      "1073180\n",
      "1073215\n",
      "1073196\n",
      "1073222\n",
      "1073200\n",
      "1073220\n",
      "1073124\n",
      "1073196\n",
      "1073197\n",
      "1073088\n",
      "1073072\n",
      "1073216\n",
      "1073205\n",
      "1073210\n",
      "1073176\n",
      "1073215\n",
      "1073193\n",
      "1073214\n",
      "1073205\n",
      "1073220\n",
      "1073214\n",
      "1073222\n",
      "1073205\n",
      "1073220\n",
      "1073203\n",
      "1073198\n",
      "1073115\n",
      "1073194\n",
      "1073220\n",
      "1073208\n",
      "1073216\n",
      "1067274\n",
      "1073222\n",
      "1073220\n",
      "1073215\n",
      "1073215\n",
      "1073166\n",
      "1073184\n",
      "1073215\n",
      "1073222\n",
      "1073215\n",
      "1073222\n",
      "1073222\n",
      "1073214\n",
      "1073216\n",
      "1073220\n",
      "1072935\n",
      "1073180\n",
      "1072188\n",
      "1073220\n",
      "1073222\n",
      "1073184\n",
      "1073214\n",
      "1072942\n",
      "1070940\n",
      "1073100\n",
      "1073216\n",
      "1073000\n",
      "1073222\n",
      "1073220\n",
      "1073215\n",
      "1072017\n",
      "1073220\n",
      "1073190\n",
      "1073048\n",
      "1073216\n",
      "1073065\n",
      "1073204\n",
      "1073205\n",
      "1073205\n",
      "1073214\n",
      "1072924\n",
      "1073215\n",
      "1073176\n",
      "1073196\n",
      "1073220\n",
      "1073220\n",
      "1073160\n",
      "1073200\n",
      "1072193\n",
      "1073212\n",
      "1073219\n",
      "1073220\n",
      "1073219\n",
      "1073219\n",
      "1073196\n",
      "1073220\n",
      "1072530\n",
      "1073205\n",
      "1073094\n",
      "1073214\n",
      "1073193\n",
      "1073220\n",
      "1073006\n",
      "1073200\n",
      "1073220\n",
      "1072479\n",
      "1073208\n",
      "1073145\n",
      "1072683\n",
      "1073222\n",
      "1073016\n",
      "1073220\n",
      "1073220\n",
      "1073196\n",
      "1073184\n",
      "1073180\n",
      "1072929\n",
      "1073144\n",
      "1073139\n",
      "1073204\n",
      "1073210\n",
      "1073216\n",
      "1073149\n",
      "1073198\n",
      "1073216\n",
      "1073208\n",
      "1073196\n",
      "1073222\n",
      "1073170\n",
      "1073210\n",
      "1073220\n",
      "1073220\n",
      "1073139\n",
      "1073222\n",
      "1071174\n",
      "1073115\n",
      "1073210\n",
      "1073220\n",
      "1073216\n",
      "1073144\n",
      "1073220\n",
      "1073072\n",
      "1073210\n",
      "1073220\n",
      "1073169\n",
      "1072932\n",
      "1073025\n",
      "1072808\n",
      "1073173\n",
      "1073220\n",
      "1073220\n",
      "1073136\n",
      "1073160\n",
      "1072820\n",
      "1073210\n",
      "1073088\n",
      "1073222\n",
      "1073215\n",
      "1073216\n",
      "1073198\n",
      "1071665\n",
      "1073072\n",
      "1073065\n",
      "1070784\n",
      "1073220\n",
      "1073196\n",
      "1073220\n",
      "1073142\n",
      "1073180\n",
      "1073193\n",
      "1073220\n",
      "1073194\n",
      "1073220\n",
      "1072800\n",
      "1073198\n",
      "1073088\n",
      "1073202\n",
      "1073202\n",
      "1073210\n",
      "1073142\n",
      "1073202\n",
      "1073220\n",
      "1073220\n",
      "1073184\n",
      "1073162\n",
      "1073190\n",
      "1072055\n",
      "1073208\n",
      "1073160\n",
      "1068496\n",
      "1073212\n",
      "1073222\n",
      "1073196\n",
      "1073203\n",
      "1073215\n",
      "1073220\n",
      "1073212\n",
      "1073220\n",
      "1073216\n",
      "1073208\n",
      "1073220\n",
      "1073205\n",
      "1073196\n",
      "1072665\n",
      "1073220\n",
      "1073203\n",
      "1073220\n",
      "1073216\n",
      "1072624\n",
      "1073198\n",
      "1073210\n",
      "1073111\n",
      "1072881\n",
      "1073222\n",
      "1073088\n",
      "1072856\n",
      "1073210\n",
      "1073215\n",
      "1073222\n",
      "1073222\n",
      "1073072\n",
      "1073214\n",
      "1073034\n",
      "1072125\n",
      "1073214\n",
      "1073058\n",
      "1073160\n",
      "1073100\n",
      "1073220\n",
      "1073220\n",
      "1073220\n",
      "1073215\n",
      "1073196\n",
      "1073220\n",
      "1055795\n",
      "1073220\n",
      "1073220\n",
      "1067648\n",
      "1072904\n",
      "1073184\n",
      "1073204\n",
      "1073202\n",
      "1073105\n",
      "1072892\n",
      "1073219\n",
      "1073094\n",
      "1073222\n",
      "1073098\n",
      "1073215\n",
      "1073160\n",
      "1073176\n",
      "1073088\n",
      "1050975\n",
      "1072632\n",
      "1073216\n",
      "1073220\n",
      "1073175\n",
      "1073220\n",
      "1073220\n",
      "1073220\n",
      "1071840\n",
      "1073163\n",
      "1073200\n",
      "1073220\n",
      "1073203\n",
      "1073184\n",
      "1073200\n",
      "1073198\n",
      "1073215\n",
      "1073216\n",
      "1073215\n",
      "1073088\n",
      "1073198\n",
      "1073196\n",
      "1073184\n",
      "1073204\n",
      "1072745\n",
      "1073215\n",
      "1073065\n",
      "1073216\n",
      "1073200\n",
      "1073219\n",
      "1073112\n",
      "1073196\n",
      "1073208\n",
      "1073215\n",
      "1073142\n",
      "1073196\n",
      "1073206\n",
      "1073212\n",
      "1073220\n",
      "1073222\n",
      "1072478\n",
      "1073222\n",
      "1073150\n",
      "1073216\n",
      "1073193\n",
      "1073204\n",
      "1073222\n",
      "1073180\n",
      "1073215\n",
      "1073173\n",
      "1073196\n",
      "1072665\n",
      "1072560\n",
      "1073220\n",
      "1073146\n",
      "1073205\n",
      "1073222\n",
      "1073169\n",
      "1073200\n",
      "1073204\n",
      "1073202\n",
      "1073160\n",
      "1073210\n",
      "1069920\n",
      "1073176\n",
      "1073214\n",
      "1073000\n",
      "1073220\n",
      "1073222\n",
      "1073184\n",
      "1073220\n",
      "1073180\n",
      "1071389\n",
      "1073220\n",
      "1073196\n",
      "1072960\n",
      "1073220\n",
      "1073176\n",
      "1073088\n",
      "1073219\n",
      "1073200\n",
      "1073216\n",
      "1073215\n",
      "1073196\n",
      "1073176\n",
      "1073208\n",
      "1073222\n",
      "1073200\n",
      "1073196\n",
      "1073216\n",
      "1073214\n",
      "1073184\n",
      "1072950\n",
      "1072764\n",
      "1073142\n",
      "1073212\n",
      "1073065\n",
      "1073048\n",
      "1073216\n",
      "1073044\n",
      "1073200\n",
      "1073220\n",
      "1073190\n",
      "1073125\n",
      "1073220\n",
      "1073222\n",
      "1073220\n",
      "1073142\n",
      "1073125\n",
      "1073208\n",
      "1073216\n",
      "1073088\n",
      "1072974\n",
      "1073220\n",
      "1073215\n",
      "1073196\n",
      "1073216\n",
      "1073220\n",
      "1073161\n",
      "1072968\n",
      "1072512\n",
      "1073220\n",
      "1073215\n",
      "1073220\n",
      "1073216\n",
      "1073094\n",
      "1073202\n",
      "1073204\n",
      "1069301\n",
      "1073215\n",
      "1073208\n",
      "1071954\n",
      "1073220\n",
      "1073214\n",
      "1073215\n",
      "1073193\n",
      "1073216\n",
      "1073215\n",
      "1073222\n",
      "1073204\n",
      "1073219\n",
      "1073200\n",
      "1073200\n",
      "1073210\n",
      "1072665\n",
      "1073220\n",
      "1073214\n",
      "1073222\n",
      "1072104\n",
      "1073000\n",
      "1073088\n",
      "1073160\n",
      "1073222\n",
      "1073125\n",
      "1072104\n",
      "1073050\n",
      "1073222\n",
      "1073216\n",
      "1073080\n",
      "1073152\n",
      "1073196\n",
      "1073203\n",
      "1073072\n",
      "1072338\n",
      "1072762\n",
      "1073190\n",
      "1073202\n",
      "1073220\n",
      "1073157\n",
      "1073220\n",
      "1073220\n",
      "1073215\n",
      "1073136\n",
      "1073215\n",
      "1073220\n",
      "1073220\n",
      "1073038\n",
      "1073220\n",
      "1073220\n",
      "1072704\n",
      "1073220\n",
      "1073212\n",
      "1073220\n",
      "1073052\n",
      "1073176\n",
      "1071950\n",
      "1073216\n",
      "1073091\n",
      "1073220\n",
      "1073197\n",
      "1073220\n",
      "1071708\n",
      "1073204\n",
      "1073212\n",
      "1073205\n",
      "1073215\n",
      "1073162\n",
      "1073220\n",
      "1073222\n",
      "1073220\n",
      "1073220\n",
      "1073088\n",
      "1073214\n",
      "1073202\n",
      "1073210\n",
      "1072134\n",
      "1073214\n",
      "1070794\n",
      "1073196\n",
      "1073220\n",
      "1073150\n",
      "1073202\n",
      "1072055\n",
      "1073121\n",
      "1073215\n",
      "1073205\n",
      "1073210\n",
      "1073088\n",
      "1073220\n",
      "1073214\n",
      "1073040\n",
      "1073216\n",
      "1073220\n",
      "1071980\n",
      "1073220\n",
      "1054560\n",
      "1073210\n",
      "1073216\n",
      "1073175\n",
      "1073160\n",
      "1073157\n",
      "1073072\n",
      "1073103"
     ]
    }
   ],
   "source": [
    "f = 'adID'\n",
    "va = tr_ori.sample(frac=.1, random_state=3)\n",
    "tr = tr_ori.drop(va.index, axis=0)\n",
    "\n",
    "va_y = va.label.values.reshape(-1,1)\n",
    "tr_y = tr.label.values.reshape(-1,1)\n",
    "va_x = va[f].values.reshape(-1,1)\n",
    "tr_x = tr[f].values.reshape(-1,1)\n",
    "\n",
    "va_ = va.groupby(f).apply(lambda df: np.mean(df.label))\n",
    "tr_ = tr.groupby(f).apply(lambda df: np.mean(df.label))\n",
    "\n",
    "\n",
    "tr_stat = tr.groupby(f).apply(lambda df: len(df))\n",
    "\n",
    "print(tr_stat.values)\n",
    "total_tr = 2*max(tr_stat.values)\n",
    "new_x = []\n",
    "new_y = []\n",
    "for cate,occ in zip(tr_stat.index, tr_stat.values):\n",
    "    tmp = tr.loc[tr[f]==cate]\n",
    "    x = tmp[f].values\n",
    "    y = tmp.label.values\n",
    "    x = list(x)\n",
    "    y = list(y)\n",
    "    x = x*(int(total_tr/len(x)))\n",
    "    y = y*(int(total_tr/len(y))) \n",
    "    print(len(x))   \n",
    "    new_x += x\n",
    "    new_y += y\n",
    "new_x = np.array(new_x).reshape(-1,1)\n",
    "new_y = np.array(new_y).reshape(-1,1)\n",
    "print('Length of new x:', len(new_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-22bbf31d49d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# no ajust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m323\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# no ajust\n",
    "np.random.seed(323)\n",
    "i = Input(shape=(1,))\n",
    "o = Embedding(np.max(tr_x)+1, 64)(i)\n",
    "o = Flatten()(o)\n",
    "o = Dense(64, activation='tanh')(o)\n",
    "o = Dense(1, activation='sigmoid')(o)\n",
    "model_ = Model(i,o)\n",
    "model_.summary()\n",
    "model_.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "model_.fit(tr_x, tr_y,validation_data=(va_x,va_y), verbose=1, epochs=2, batch_size=1024,  shuffle=True)\n",
    "\n",
    "print('\\nUnbalanced model predict:\\n', model_.predict(va_.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1, 64)             32256     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 36,481\n",
      "Trainable params: 36,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 47645902 samples, validate on 374953 samples\n",
      "Epoch 1/2\n",
      "47645902/47645902 [==============================] - 59s - loss: 0.2011 - binary_crossentropy: 0.2011 - val_loss: 0.1117 - val_binary_crossentropy: 0.1117\n",
      "Epoch 2/2\n",
      "47645902/47645902 [==============================] - 59s - loss: 0.1995 - binary_crossentropy: 0.1995 - val_loss: 0.1117 - val_binary_crossentropy: 0.1117\n",
      "\n",
      "Balanced model predict:\n",
      " [[  4.17645127e-01]\n",
      " [  1.55870942e-02]\n",
      " [  3.00532933e-02]\n",
      " [  3.64281386e-02]\n",
      " [  4.65930067e-02]\n",
      " [  7.35809701e-03]\n",
      " [  3.13882865e-02]\n",
      " [  9.29833427e-02]\n",
      " [  2.05584522e-02]\n",
      " [  2.83221584e-02]\n",
      " [  3.91063057e-02]\n",
      " [  2.12164193e-01]\n",
      " [  3.70186062e-05]\n",
      " [  3.28653455e-02]]\n",
      "ideal-model ideal-model_ model_-model\n",
      "-0.00004000, 0.00016449, -0.00020449\n",
      "appCategory\n",
      "0      0.261278\n",
      "2      0.002094\n",
      "101    0.007664\n",
      "104    0.005798\n",
      "106   -0.001305\n",
      "108   -0.000359\n",
      "201    0.004386\n",
      "203    0.016940\n",
      "209    0.001595\n",
      "301    0.002648\n",
      "402    0.005509\n",
      "407   -0.005810\n",
      "408   -0.004685\n",
      "503    0.001599\n",
      "dtype: float64 \n",
      "Balanced model\n",
      " appCategory\n",
      "0      0.026799\n",
      "2     -0.000282\n",
      "101    0.000763\n",
      "104   -0.001473\n",
      "106   -0.046593\n",
      "108   -0.001530\n",
      "201    0.000243\n",
      "203   -0.000379\n",
      "209   -0.000109\n",
      "301   -0.001419\n",
      "402   -0.001686\n",
      "407   -0.018827\n",
      "408   -0.000037\n",
      "503   -0.006398\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# balanced\n",
    "np.random.seed(323)\n",
    "i = Input(shape=(1,))\n",
    "o = Embedding(np.max(new_x)+1, 64)(i)\n",
    "o = Flatten()(o)\n",
    "o = Dense(64, activation='tanh')(o)\n",
    "o = Dense(1, activation='sigmoid')(o)\n",
    "model = Model(i,o)\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "model.fit(new_x, new_y,validation_data=(va_x,va_y), verbose=1, epochs=2, batch_size=10240,  shuffle=True)\n",
    "\n",
    "print('\\nBalanced model predict:\\n', model.predict(va_.index))\n",
    "\n",
    "va_df = va_.to_frame().reset_index()\n",
    "dict_prob = va_df.set_index(va_df[f]).to_dict()[0]\n",
    "\n",
    "ideal_loss = log_loss(va_y, np.array([dict_prob[c[0]] for c in va_x]).reshape(-1,1))\n",
    "model_loss = log_loss(va_y, model.predict(va_x ))\n",
    "model_loss_ = log_loss(va_y, model_.predict(va_x))\n",
    "print('ideal-model', 'ideal-model_', 'model_-model')\n",
    "print('%.8f, %.8f, %.8f'%(ideal_loss-model_loss , model_loss_-model_loss,ideal_loss-model_loss_))\n",
    "\n",
    "print(va_-np.ravel(model_.predict(va_.index)), '\\nBalanced model\\n',va_-np.ravel(model.predict(va_.index)) )\n",
    "\n",
    "\n",
    "model.save('balanced_tl_%s_%.6f.h5'%(f,ideal_loss-model_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "va_df = va_.to_frame().reset_index()\n",
    "dict_prob = va_df.set_index(va_df[f]).to_dict()[0]\n",
    "\n",
    "ideal_loss = log_loss(va_y, np.array([dict_prob[c[0]] for c in va_x]).reshape(-1,1))\n",
    "model_loss = log_loss(va_y, model.predict(va_x ))\n",
    "model_loss_ = log_loss(va_y, model_.predict(va_x))\n",
    "print('ideal-model', 'ideal-model_', 'model_-model')\n",
    "print('%.8f, %.8f, %.8f'%(ideal_loss-model_loss , model_loss_-model_loss,ideal_loss-model_loss_))\n",
    "\n",
    "print(va_-np.ravel(model_.predict(va_.index)), '\\nBalanced model\\n',va_-np.ravel(model.predict(va_.index)) )\n",
    "\n",
    "\n",
    "model.save('balanced_tl_%s_%.6f.h5'%(f,ideal_loss-model_loss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
